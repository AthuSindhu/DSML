{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exp_6_new.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP5/wCyeNBHmd5bG2l3owv9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AthuSindhu/DSML/blob/main/Exp_6_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aim: Program to implement Naïve Bayes Algorithm using any standard dataset available in the public domain and find the accuracy of the algorithm\n",
        "\n",
        "Short notes: Naive Bayes\n",
        "\n",
        "Bayes’ Theorem provides a way that we can calculate the probability of a piece of data belonging to a given class, given our prior knowledge. Bayes’ Theorem is stated as:\n",
        "\n",
        "P(class|data) = (P(data|class) * P(class)) / P(data)\n",
        "\n",
        "Where P(class|data) is the probability of class given the provided data.\n",
        "\n",
        "We are using Iris Dataset. The Iris Flower Dataset involves predicting the flower species given measurements of iris flowers.\n",
        "\n",
        "It is a multiclass classification problem. The number of observations for each class is balanced. There are 150 observations with 4 input variables and 1 output variable. The variable names are as follows:\n",
        "\n",
        "Sepal length in cm.\n",
        "\n",
        "Sepal width in cm.\n",
        "\n",
        "Petal length in cm.\n",
        "\n",
        "Petal width in cm., and\n",
        "\n",
        "Class.\n",
        "\n",
        "Algorithm:\n",
        "\n",
        "Step 1: Separate By Class.\n",
        "\n",
        "Step 2: Summarize Dataset.\n",
        "\n",
        "Step 3: Summarize Data By Class.\n",
        "\n",
        "Step 4: Gaussian Probability Density Function.\n",
        "\n",
        "Step 5: Class Probabilities."
      ],
      "metadata": {
        "id": "3P4ggx8LtpUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn import neighbors, datasets, preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "X, y = iris.data[:, :], iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, random_state = 0, train_size = 0.7)"
      ],
      "metadata": {
        "id": "7BZFV4VKtsZo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "metadata": {
        "id": "qxbpxxCHt7nF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this step, we introduce the class GaussianNB that is used from the sklearn.naive_bayes library. Here, we have used a Gaussian model, there are several other models such as Bernoulli, Categorical and Multinomial. Here, we assign the GaussianNB class to the variable classifier and fit the X_train and y_train values to it for training purpose."
      ],
      "metadata": {
        "id": "aei80VyduNta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB, CategoricalNB\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score \n",
        "scores = []\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(X_train, y_train)\n",
        "y_pred = classifier.predict(X_test) \n",
        "scores.append(accuracy_score(y_test, y_pred))\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-x9ttO-uQM4",
        "outputId": "ef4fb4f2-09b4-4381-c64f-bf575f2ee4b5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[15,  0,  0],\n",
              "       [ 0, 15,  0],\n",
              "       [ 0,  1, 14]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier1 = BernoulliNB()\n",
        "classifier1.fit(X_train, y_train)\n",
        "y_pred = classifier.predict(X_test) \n",
        "scores.append(accuracy_score(y_test, y_pred))\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lThosKP0ubZq",
        "outputId": "9e5f86db-af27-4062-af68-ea49f8521496"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[15,  0,  0],\n",
              "       [ 0, 15,  0],\n",
              "       [ 0,  1, 14]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above confusion matrix, we infer that, out of 45 test set data, 44 were correctly classified and only 1 was incorrectly classified. This gives us a high accuracy of 97.7%."
      ],
      "metadata": {
        "id": "vYH__5TZufDS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#classifier1 = CategoricalNB()\n",
        "#classifier1.fit(X_train, y_train)\n",
        "#y_pred = classifier.predict(X_test) \n",
        "#scores.append(accuracy_score(y_test, y_pred))\n",
        "#ValueError: Negative values in data passed to CategoricalNB (input X)"
      ],
      "metadata": {
        "id": "cNx6gIVbufnn"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNP9SQylus-Y",
        "outputId": "dabe88cc-06fc-4279-a3b2-15e25b8f25ee"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.9777777777777777, 0.9777777777777777]\n"
          ]
        }
      ]
    }
  ]
}